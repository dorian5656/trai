#!/usr/bin/env python
# -*- coding: utf-8 -*-
# æ–‡ä»¶åï¼šbackend/app/routers/ai/image_func.py
# ä½œè€…ï¼šliuhd
# æ—¥æœŸï¼š2026-01-28
# æè¿°ï¼šAI å›¾åƒå¤„ç†ä¸å¤šæ¨¡æ€ä¸šåŠ¡é€»è¾‘

import httpx
import os
import time
import uuid
import json
from io import BytesIO
from pathlib import Path
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Union
from backend.app.config import settings
from backend.app.utils.logger import logger
from backend.app.utils.modelscope_utils import ModelScopeUtils
from backend.app.utils.upload_utils import UploadUtils
from backend.app.routers.upload.upload_func import UserImage
from backend.app.utils.pg_utils import PGUtils
from sqlalchemy import text

# å…¨å±€ç¼“å­˜æ¨¡å‹ pipeline
_z_image_pipeline = None


# =============================================================================
# Schema å®šä¹‰ (Image/Multimodal)
# =============================================================================

class ImageContent(BaseModel):
    """
    å¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
    """
    type: str = Field(..., description="å†…å®¹ç±»å‹: 'text' (æ–‡æœ¬) æˆ– 'image' (å›¾ç‰‡)", examples=["text", "image"])
    text: Optional[str] = Field(None, description="å½“ type='text' æ—¶å¿…å¡«ï¼Œè¡¨ç¤ºæ–‡æœ¬å†…å®¹", examples=["Describe this image."])
    image: Optional[str] = Field(None, description="å½“ type='image' æ—¶å¿…å¡«ï¼Œæ”¯æŒ URL (http/file) æˆ– Base64 (data:image/...)", examples=["https://example.com/image.jpg"])

    model_config = {
        "json_schema_extra": {
            "example": {
                "type": "text",
                "text": "What is in this picture?",
                "image": None
            }
        }
    }

class MultimodalMessage(BaseModel):
    """
    å¤šæ¨¡æ€å¯¹è¯æ¶ˆæ¯
    """
    role: str = Field(..., description="è§’è‰² (user/assistant/system)", examples=["user"])
    content: List[ImageContent] = Field(..., description="æ¶ˆæ¯å†…å®¹ (æ”¯æŒçº¯æ–‡æœ¬æˆ–å¤šæ¨¡æ€åˆ—è¡¨)")

    model_config = {
        "json_schema_extra": {
            "example": {
                "role": "user",
                "content": [
                    {"type": "image", "image": "https://example.com/cat.jpg"},
                    {"type": "text", "text": "What animal is this?"}
                ]
            }
        }
    }

class ImageChatRequest(BaseModel):
    """
    AI å›¾åƒå¯¹è¯è¯·æ±‚ (Qwen-VL ç­‰)
    """
    messages: List[MultimodalMessage] = Field(..., description="å†å²æ¶ˆæ¯åˆ—è¡¨")
    model: str = Field("Qwen/Qwen3-VL-4B-Instruct", description="æ¨¡å‹åç§°", examples=["Qwen/Qwen3-VL-4B-Instruct"])
    temperature: float = Field(0.7, description="æ¸©åº¦ç³»æ•°", examples=[0.7])
    max_tokens: int = Field(512, description="æœ€å¤§ç”Ÿæˆ Token æ•°", examples=[512])

    model_config = {
        "json_schema_extra": {
            "example": {
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image", "image": "https://example.com/demo.jpg"},
                            {"type": "text", "text": "Describe this image."}
                        ]
                    }
                ],
                "model": "Qwen/Qwen3-VL-4B-Instruct",
                "temperature": 0.7,
                "max_tokens": 512
            }
        }
    }

class ImageChatResponse(BaseModel):
    """
    AI å›¾åƒå¯¹è¯å“åº”
    """
    reply: str = Field(..., description="AI å›å¤å†…å®¹")
    model: str = Field(..., description="ä½¿ç”¨çš„æ¨¡å‹")
    usage: Dict[str, Any] = Field({}, description="Token ä½¿ç”¨ç»Ÿè®¡")

class ImageGenRequest(BaseModel):
    """
    æ–‡ç”Ÿå›¾è¯·æ±‚
    """
    prompt: str = Field(..., description="æç¤ºè¯", examples=["A futuristic city skyline at sunset"])
    model: str = Field("Z-Image-Turbo", description="æ¨¡å‹åç§°", examples=["Z-Image-Turbo"])
    size: str = Field("1024x1024", description="å›¾ç‰‡å°ºå¯¸", examples=["1024x1024"])
    n: int = Field(1, description="ç”Ÿæˆæ•°é‡", examples=[1])

    model_config = {
        "json_schema_extra": {
            "example": {
                "prompt": "A cute cat playing piano",
                "model": "Z-Image-Turbo",
                "size": "1024x1024",
                "n": 1
            }
        }
    }

class ImageGenResponse(BaseModel):
    """
    æ–‡ç”Ÿå›¾å“åº”
    """
    created: int = Field(..., description="åˆ›å»ºæ—¶é—´æˆ³")
    data: List[Dict[str, str]] = Field(..., description="å›¾ç‰‡æ•°æ®åˆ—è¡¨ [{'url': '...'}, ...]")

# =============================================================================
# Manager å®ç°
# =============================================================================

class ImageManager:
    """
    AI å›¾åƒ/å¤šæ¨¡æ€ä¸šåŠ¡ç®¡ç†å™¨
    """
    
    @staticmethod
    async def get_image_history(user_id: str, page: int = 1, size: int = 20) -> Dict[str, Any]:
        """
        è·å–æ–‡ç”Ÿå›¾å†å²è®°å½•
        """
        try:
            engine = PGUtils.get_engine()
            async with engine.begin() as conn:
                # ç»Ÿè®¡æ€»æ•° (ä»…æŸ¥è¯¢ source='generated')
                total = await conn.execute(
                    text("SELECT COUNT(*) FROM user_images WHERE user_id = :user_id AND source = 'generated' AND is_deleted = FALSE"),
                    {"user_id": user_id}
                )
                total_count = total.scalar()
                
                # åˆ†é¡µæŸ¥è¯¢
                offset = (page - 1) * size
                result = await conn.execute(
                    text("""
                        SELECT id, url, prompt, meta_data, created_at
                        FROM user_images 
                        WHERE user_id = :user_id AND source = 'generated' AND is_deleted = FALSE
                        ORDER BY created_at DESC
                        LIMIT :limit OFFSET :offset
                    """),
                    {"user_id": user_id, "limit": size, "offset": offset}
                )
                
                items = []
                for row in result:
                    meta = row.meta_data if row.meta_data else {}
                    if isinstance(meta, str):
                        try:
                            meta = json.loads(meta)
                        except:
                            meta = {}
                            
                    items.append({
                        "id": str(row.id),
                        "url": row.url,
                        "prompt": row.prompt,
                        "model": meta.get("model", "unknown"),
                        "created_at": row.created_at.strftime("%Y-%m-%d %H:%M:%S") if row.created_at else None
                    })
                    
                return {
                    "total": total_count,
                    "items": items,
                    "page": page,
                    "size": size
                }
        except Exception as e:
            logger.error(f"è·å–æ–‡ç”Ÿå›¾å†å²å¤±è´¥: {e}")
            raise ValueError(f"Failed to fetch image history: {e}")

    @staticmethod
    async def delete_image_history(image_id: str, user_id: str) -> None:
        """
        åˆ é™¤æ–‡ç”Ÿå›¾å†å² (è½¯åˆ é™¤)
        """
        try:
            engine = PGUtils.get_engine()
            async with engine.begin() as conn:
                # æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨ä¸”å±äºè¯¥ç”¨æˆ·
                result = await conn.execute(
                    text("SELECT id FROM user_images WHERE id = :id AND user_id = :user_id AND is_deleted = FALSE"),
                    {"id": image_id, "user_id": user_id}
                )
                if not result.scalar():
                    raise ValueError("Image not found or permission denied")

                # æ‰§è¡Œè½¯åˆ é™¤
                await conn.execute(
                    text("UPDATE user_images SET is_deleted = TRUE, updated_at = (NOW() AT TIME ZONE 'Asia/Shanghai') WHERE id = :id"),
                    {"id": image_id}
                )
                logger.info(f"æ–‡ç”Ÿå›¾è®°å½•å·²åˆ é™¤: {image_id}")
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ç”Ÿå›¾å†å²å¤±è´¥: {e}")
            raise e

    @staticmethod
    async def chat_with_image_stream(request: ImageChatRequest):
        """
        å¤šæ¨¡æ€å¯¹è¯ (Qwen-VL) - æµå¼å“åº”
        """
        try:
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            # æ³¨æ„: Pydantic çš„ model_dump() é»˜è®¤ä¼šåŒ…å«æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬ None å€¼çš„å­—æ®µ
            # Qwen-VL utils çš„ process_vision_info å¯¹ None å€¼æ•æ„Ÿï¼Œç‰¹åˆ«æ˜¯ 'image' å­—æ®µ
            # å¦‚æœ type='text'ï¼Œimage å­—æ®µåº”è¯¥æ˜¯ç¼ºå¤±çš„ï¼Œè€Œä¸æ˜¯ None
            
            messages = []
            for msg in request.messages:
                content_list = []
                for item in msg.content:
                    content_item = {"type": item.type}
                    if item.text is not None:
                        content_item["text"] = item.text
                    if item.image is not None:
                        content_item["image"] = item.image
                    content_list.append(content_item)
                
                messages.append({
                    "role": msg.role,
                    "content": content_list
                })
            
            # å¤„ç†æ¨¡å‹åç§°
            model_name = request.model
            if model_name == "Qwen3-VL-4B-Instruct":
                model_name = "Qwen/Qwen3-VL-4B-Instruct"
            elif model_name == "Qwen3-VL-8B-Instruct":
                model_name = "Qwen/Qwen3-VL-8B-Instruct"

            # è¿™é‡Œçš„ chat_completion_stream æ˜¯ä¸€ä¸ª async generator
            async for chunk in ModelScopeUtils.chat_completion_stream(
                messages=messages,
                model_name=model_name,
                max_new_tokens=request.max_tokens
            ):
                yield chunk
            
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€æµå¼å¯¹è¯å¤±è´¥: {e}")
            yield f"[ERROR: {str(e)}]"

    @staticmethod
    async def chat_with_image(request: ImageChatRequest) -> ImageChatResponse:
        """
        å¤šæ¨¡æ€å¯¹è¯ (Qwen-VL) - æœ¬åœ°æ¨ç†
        """
        try:
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ (å¦‚æœéœ€è¦é€‚é…å‰ç«¯æ ¼å¼åˆ° Qwen æ ¼å¼)
            messages = []
            for msg in request.messages:
                content_list = []
                for item in msg.content:
                    content_item = {"type": item.type}
                    if item.text is not None:
                        content_item["text"] = item.text
                    if item.image is not None:
                        content_item["image"] = item.image
                    content_list.append(content_item)
                
                messages.append({
                    "role": msg.role,
                    "content": content_list
                })
            
            # å¤„ç†æ¨¡å‹åç§°
            model_name = request.model
            if model_name == "Qwen3-VL-4B-Instruct":
                model_name = "Qwen/Qwen3-VL-4B-Instruct"
            elif model_name == "Qwen3-VL-8B-Instruct":
                model_name = "Qwen/Qwen3-VL-8B-Instruct"

            reply = await ModelScopeUtils.chat_completion(
                messages=messages,
                model_name=model_name,
                max_new_tokens=request.max_tokens
            )
            
            return ImageChatResponse(
                reply=reply,
                model=model_name,
                usage={"prompt_tokens": 0, "completion_tokens": 0}
            )
            
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€å¯¹è¯å¤±è´¥: {e}")
            raise ValueError(f"Multimodal chat failed: {e}")

    @staticmethod
    async def generate_image(request: ImageGenRequest, user_id: str = "anonymous") -> ImageGenResponse:
        """
        æ–‡ç”Ÿå›¾ (FLUX / Z-Image ç­‰)
        """
        # å¦‚æœè¯·æ±‚æŒ‡å®š Z-Image æ¨¡å‹ï¼Œèµ°æœ¬åœ°è°ƒç”¨
        if "Z-Image" in request.model or "Tongyi-MAI" in request.model:
             return await ImageManager._generate_z_image_local(request, user_id)

        # æ„é€ è¯·æ±‚ä½“
        payload = {
            "model": request.model,
            "prompt": request.prompt,
            "size": request.size,
            "n": request.n
        }
        
        api_base = settings.DIFY_API_BASE_URL
        api_key = settings.AI_API_KEY
        
        # æ„é€  URL (Dify OpenAI å…¼å®¹æ¥å£é€šå¸¸åœ¨ /v1 ä¸‹)
        # å¦‚æœé…ç½®ä¸­æœ‰ /v1ï¼Œåˆ™ç›´æ¥æ‹¼æ¥; å¦åˆ™å°è¯•è‡ªåŠ¨é€‚é…
        url = f"{api_base}/images/generations"
        if api_base.endswith("/"):
            url = f"{api_base}images/generations"

        logger.info(f"æ­£åœ¨è°ƒç”¨æ–‡ç”Ÿå›¾æ¨¡å‹: {request.model}, URL: {url}")

        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    url,
                    json=payload,
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    }
                )
                
                if response.status_code != 200:
                    logger.error(f"ç”Ÿå›¾å¤±è´¥: {response.text}")
                    raise Exception(f"Image Gen API Error: {response.status_code} - {response.text}")
                
                try:
                    data = response.json()
                except Exception:
                    logger.error(f"å“åº”è§£æå¤±è´¥: {response.text[:200]}")
                    raise Exception(f"Invalid JSON response: {response.text[:200]}")
                
                # è®°å½•åˆ° user_images è¡¨
                try:
                    engine = PGUtils.get_engine()
                    async with engine.begin() as conn:
                        for item in data.get("data", []):
                            img_url = item.get("url")
                            if img_url:
                                await conn.execute(
                                    text("""
                                        INSERT INTO user_images (user_id, filename, s3_key, url, module, source, prompt, meta_data)
                                        VALUES (:user_id, :filename, :s3_key, :url, :module, :source, :prompt, :meta_data)
                                    """),
                                    {
                                        "user_id": user_id,
                                        "filename": f"dify_gen_{int(time.time())}_{uuid.uuid4().hex[:8]}.png",
                                        "s3_key": img_url, # è¿œç¨‹URLä½œä¸ºkey
                                        "url": img_url,
                                        "module": "gen",
                                        "source": "generated",
                                        "prompt": request.prompt,
                                        "meta_data": json.dumps({"model": request.model, "provider": "dify"})
                                    }
                                )
                                # å‘é€ Feishu é€šçŸ¥ (å›¾æ–‡)
                                try:
                                    from backend.app.utils.feishu_utils import feishu_bot
                                    
                                    # 1. å°è¯•ä¸‹è½½å›¾ç‰‡ä»¥è·å– bytes
                                    async with httpx.AsyncClient() as client:
                                        resp = await client.get(img_url)
                                        if resp.status_code == 200:
                                            img_bytes = resp.content
                                            # 2. ä¸Šä¼ åˆ°é£ä¹¦è·å– image_key
                                            image_key = feishu_bot.upload_image(img_bytes)
                                            
                                            if image_key:
                                                # 3. æ„é€ å¯Œæ–‡æœ¬æ¶ˆæ¯
                                                post_content = [
                                                    [{"tag": "text", "text": f"Prompt: {request.prompt}"}],
                                                    [{"tag": "text", "text": f"Model: {request.model}"}],
                                                    [{"tag": "text", "text": f"URL: {img_url}"}],
                                                    [{"tag": "img", "image_key": image_key}]
                                                ]
                                                feishu_bot.send_webhook_post(
                                                    title="ğŸ¨ [æ–‡ç”Ÿå›¾å®Œæˆ]",
                                                    content=post_content,
                                                    webhook_token=settings.FEISHU_IMAGE_GEN_WEBHOOK_TOKEN
                                                )
                                            else:
                                                # ä¸Šä¼ å¤±è´¥ï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬
                                                notify_content = f"ğŸ¨ [æ–‡ç”Ÿå›¾å®Œæˆ]\nğŸ“ Prompt: {request.prompt}\nğŸ¤– Model: {request.model}\nğŸ–¼ï¸ URL: {img_url}\n(å›¾ç‰‡ä¸Šä¼ é£ä¹¦å¤±è´¥)"
                                                feishu_bot.send_webhook_message(notify_content, webhook_token=settings.FEISHU_IMAGE_GEN_WEBHOOK_TOKEN)
                                        else:
                                            # ä¸‹è½½å¤±è´¥
                                            notify_content = f"ğŸ¨ [æ–‡ç”Ÿå›¾å®Œæˆ]\nğŸ“ Prompt: {request.prompt}\nğŸ¤– Model: {request.model}\nğŸ–¼ï¸ URL: {img_url}\n(å›¾ç‰‡ä¸‹è½½å¤±è´¥)"
                                            feishu_bot.send_webhook_message(notify_content, webhook_token=settings.FEISHU_IMAGE_GEN_WEBHOOK_TOKEN)

                                except Exception as fe:
                                    logger.error(f"å‘é€é£ä¹¦é€šçŸ¥å¤±è´¥: {fe}")

                except Exception as e:
                    logger.error(f"Failed to save generated image to DB: {e}")

                return ImageGenResponse(
                    created=data.get("created", 0),
                    data=data.get("data", [])
                )
        except Exception as e:
            logger.error(f"æ–‡ç”Ÿå›¾å¼‚å¸¸: {str(e)}")
            raise e

    @staticmethod
    async def _generate_z_image_local(request: ImageGenRequest, user_id: str = "anonymous") -> ImageGenResponse:
        """
        æœ¬åœ°è¿è¡Œ Z-Image æ¨¡å‹ (å¼‚æ­¥åŒ…è£…)
        """
        import asyncio
        loop = asyncio.get_running_loop()
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œé˜»å¡çš„ GPU æ¨ç†ä»£ç 
        images_bytes = await loop.run_in_executor(None, ImageManager._run_z_image_sync, request)
        
        images_data = []
        for img_bytes in images_bytes:
            filename = f"z_image_{uuid.uuid4()}.png"
            
            # åˆ¤æ–­æ˜¯å¦å¯ç”¨ S3 (é€šè¿‡ settings æˆ– UploadUtils å†…éƒ¨é€»è¾‘)
            # UploadUtils.save_from_bytes å†…éƒ¨å·²ç»å¤„ç†äº† S3_ENABLED çš„åˆ¤æ–­é€»è¾‘
            # ä½†æˆ‘ä»¬éœ€è¦ç¡®ä¿è¿”å›çš„æ˜¯å®Œæ•´ URL ç»™å‰ç«¯
            
            url, object_key, size = await UploadUtils.save_from_bytes(
                data=img_bytes, 
                filename=filename, 
                module="gen", 
                content_type="image/png"
            )
            
            # å¦‚æœæ˜¯æœ¬åœ°å­˜å‚¨ï¼ŒUploadUtils è¿”å›çš„æ˜¯ç›¸å¯¹è·¯å¾„ (e.g., /static/uploads/...)
            # å¦‚æœæ˜¯ S3ï¼Œè¿”å›çš„æ˜¯å®Œæ•´ URL (e.g., http://minio... or https://oss...)
            # å‰ç«¯é€šå¸¸éœ€è¦å®Œæ•´ URLï¼Œæˆ–è€…æ‹¼æ¥ BaseURL
            
            # è¿™é‡Œçš„ url å­—æ®µï¼Œå¦‚æœæ˜¯ S3 åˆ™æ˜¯å®Œæ•´é“¾æ¥ï¼›å¦‚æœæ˜¯æœ¬åœ°åˆ™æ˜¯ç›¸å¯¹è·¯å¾„
            # ä¸ºäº†æ–¹ä¾¿å‰ç«¯ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•æ‹¼æ¥æœ¬åœ° URL çš„ host
            
            final_url = url
            
            # è®°å½•åˆ° user_images è¡¨
            try:
                engine = PGUtils.get_engine()
                async with engine.begin() as conn:
                     await conn.execute(
                        text("""
                            INSERT INTO user_images (user_id, filename, s3_key, url, size, mime_type, module, source, prompt, meta_data)
                            VALUES (:user_id, :filename, :s3_key, :url, :size, :mime_type, :module, :source, :prompt, :meta_data)
                        """),
                        {
                            "user_id": user_id,
                            "filename": filename,
                            "s3_key": object_key,
                            "url": final_url,
                            "size": size,
                            "mime_type": "image/png",
                            "module": "gen",
                            "source": "generated",
                            "prompt": request.prompt,
                            "meta_data": json.dumps({"model": request.model, "provider": "z-image"})
                        }
                    )
                # å‘é€ Feishu é€šçŸ¥ (å›¾æ–‡)
                try:
                    from backend.app.utils.feishu_utils import feishu_bot
                    
                    # 1. ä¸Šä¼ åˆ°é£ä¹¦è·å– image_key (æˆ‘ä»¬å·²ç»æœ‰ img_bytes)
                    image_key = feishu_bot.upload_image(img_bytes)
                    
                    if image_key:
                        # 2. æ„é€ å¯Œæ–‡æœ¬æ¶ˆæ¯
                        post_content = [
                            [{"tag": "text", "text": f"Prompt: {request.prompt}"}],
                            [{"tag": "text", "text": f"Model: {request.model}"}],
                            [{"tag": "text", "text": f"URL: {final_url}"}],
                            [{"tag": "img", "image_key": image_key}]
                        ]
                        feishu_bot.send_webhook_post(
                            title="ğŸ¨ [æœ¬åœ°æ–‡ç”Ÿå›¾å®Œæˆ]",
                            content=post_content,
                            webhook_token=settings.FEISHU_IMAGE_GEN_WEBHOOK_TOKEN
                        )
                    else:
                         # é™çº§
                         notify_content = f"ğŸ¨ [æœ¬åœ°æ–‡ç”Ÿå›¾å®Œæˆ]\nğŸ“ Prompt: {request.prompt}\nğŸ¤– Model: {request.model}\nğŸ–¼ï¸ URL: {final_url}\n(å›¾ç‰‡ä¸Šä¼ é£ä¹¦å¤±è´¥)"
                         feishu_bot.send_webhook_message(notify_content, webhook_token=settings.FEISHU_IMAGE_GEN_WEBHOOK_TOKEN)

                except Exception as fe:
                    logger.error(f"å‘é€é£ä¹¦é€šçŸ¥å¤±è´¥: {fe}")

            except Exception as e:
                logger.error(f"Failed to save generated Z-Image to DB: {e}")

            if not url.startswith("http"):
                 # æœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•æ‹¼æ¥ (è™½ç„¶åç«¯æ— æ³•ç¡®åˆ‡çŸ¥é“å‰ç«¯è®¿é—®çš„ Hostï¼Œä½†å¯ä»¥å°½é‡æä¾›å®Œæ•´è·¯å¾„)
                 # æˆ–è€…ä¿æŒç›¸å¯¹è·¯å¾„ï¼Œç”±å‰ç«¯æ‹¼æ¥ã€‚
                 # ç”¨æˆ·è¦æ±‚ "è®°å¾—è¿”å›æœ‰ S3 åœ°å€"ï¼Œæ„å‘³ç€å¦‚æœé…ç½®äº† S3ï¼Œå¿…é¡»æ˜¯ S3 åœ°å€ã€‚
                 # UploadUtils.save_from_bytes å·²ç»åšåˆ°äº†è¿™ä¸€ç‚¹ã€‚
                 pass

            images_data.append({"url": final_url})
            logger.info(f"Generated image: {object_key} (URL: {final_url})")
            
        return ImageGenResponse(
            created=int(time.time()),
            data=images_data
        )

    @staticmethod
    def _run_z_image_sync(request: ImageGenRequest) -> List[bytes]:
        """
        Z-Image åŒæ­¥æ¨ç†é€»è¾‘ (è¿”å›å›¾ç‰‡å­—èŠ‚åˆ—è¡¨)
        """
        global _z_image_pipeline
        import torch
        from diffusers import DiffusionPipeline

        # 1. ç¡®å®šæ¨¡å‹è·¯å¾„
        base_dir = Path(__file__).resolve().parent.parent.parent.parent
        
        # è‡ªåŠ¨ä¸‹è½½/æ£€æŸ¥æ¨¡å‹
        try:
            from modelscope.hub.snapshot_download import snapshot_download
            logger.info(f"Checking/Downloading Z-Image-Turbo model...")
            # snapshot_download ä¼šè‡ªåŠ¨å¤„ç†æ–­ç‚¹ç»­ä¼ å’Œç¼“å­˜
            model_path = snapshot_download("Tongyi-MAI/Z-Image-Turbo", cache_dir=str(base_dir / "app/models"))
            logger.success(f"âœ… Z-Image-Turbo model ready at {model_path}")
        except Exception as e:
            logger.error(f"âŒ Z-Image-Turbo æ¨¡å‹ä¸‹è½½/æ£€æŸ¥å¤±è´¥: {e}")
            raise e

        # 2. åŠ è½½æ¨¡å‹ (å•ä¾‹ç¼“å­˜)
        if _z_image_pipeline is None:
             logger.info(f"Loading Z-Image model from {model_path}...")
             try:
                 dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16
                 _z_image_pipeline = DiffusionPipeline.from_pretrained(
                     str(model_path),
                     torch_dtype=dtype,
                     low_cpu_mem_usage=False
                 )
                 if torch.cuda.is_available():
                     # è‡ªåŠ¨é€‰æ‹©æ˜¾å­˜æœ€å¤§çš„ GPU
                     device = "cuda"
                     try:
                         device_count = torch.cuda.device_count()
                         max_free_memory = 0
                         best_gpu_id = 0
                         for i in range(device_count):
                             free_mem = torch.cuda.mem_get_info(i)[0]
                             if free_mem > max_free_memory:
                                 max_free_memory = free_mem
                                 best_gpu_id = i
                         device = f"cuda:{best_gpu_id}"
                         logger.info(f"Z-Image using GPU {best_gpu_id} (Free: {max_free_memory / 1024**3:.2f} GB)")
                     except Exception as e:
                         logger.warning(f"Failed to auto-select GPU, using default cuda: {e}")
                     
                     _z_image_pipeline.to(device)
                 logger.success("Z-Image model loaded successfully.")
             except Exception as e:
                 logger.error(f"Failed to load Z-Image model: {e}")
                 raise e

        # 3. ç”Ÿæˆå›¾ç‰‡
        generated_images_bytes = []
        
        logger.info(f"Start generating {request.n} images with prompt: {request.prompt[:50]}...")
        
        for i in range(request.n):
            # è§£æå°ºå¯¸ (é»˜è®¤ 1024x1024)
            width, height = 1024, 1024
            if "x" in request.size:
                try:
                    w, h = request.size.split("x")
                    width, height = int(w), int(h)
                except:
                    pass

            image = _z_image_pipeline(
                prompt=request.prompt,
                height=height,
                width=width,
                num_inference_steps=9,  # Turbo model recommended steps
                guidance_scale=0.0,     # Turbo model recommended guidance
                generator=torch.Generator("cuda" if torch.cuda.is_available() else "cpu").manual_seed(int(time.time() * 1000) % 2**32),
            ).images[0]
            
            # å°† PIL Image ä¿å­˜åˆ°å†…å­˜
            img_byte_arr = BytesIO()
            image.save(img_byte_arr, format='PNG')
            generated_images_bytes.append(img_byte_arr.getvalue())
            
        return generated_images_bytes
