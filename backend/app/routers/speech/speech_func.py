#!/usr/bin/env python
# -*- coding: utf-8 -*-
# æ–‡ä»¶åï¼šbackend/app/routers/speech/speech_func.py
# ä½œè€…ï¼šwhf
# æ—¥æœŸï¼š2026-01-30
# æè¿°ï¼šè¯­éŸ³è¯†åˆ«ä¸šåŠ¡é€»è¾‘å°è£…

import os
import sys
import shutil
import uuid
import json
import traceback
import asyncio
import numpy as np
from pathlib import Path
from fastapi import UploadFile, WebSocket, WebSocketDisconnect

# å¼•å…¥é¡¹ç›®é…ç½®å’Œæ—¥å¿—
from backend.app.config import settings
from backend.app.utils.logger import logger
from backend.app.utils.upload_utils import UploadUtils
from backend.app.utils.pg_utils import Base
from sqlalchemy import Column, String, Float, DateTime, Text, Boolean, text
from sqlalchemy.dialects.postgresql import UUID

class SpeechLog(Base):
    """è¯­éŸ³è¯†åˆ«è®°å½•è¡¨"""
    __tablename__ = "speech_logs"

    id = Column(UUID(as_uuid=True), primary_key=True, server_default=text("gen_random_uuid()"))
    user_id = Column(String(50), nullable=False, comment="ç”¨æˆ·ID")
    audio_url = Column(Text, nullable=False, comment="éŸ³é¢‘URL")
    s3_key = Column(String(500), comment="S3 Key")
    recognition_text = Column(Text, comment="è¯†åˆ«ç»“æœ")
    duration = Column(Float, comment="æ—¶é•¿(ç§’)")
    model_version = Column(String(50), default="funasr-paraformer", comment="æ¨¡å‹ç‰ˆæœ¬")
    status = Column(String(20), default="success", comment="çŠ¶æ€")
    error_msg = Column(Text, comment="é”™è¯¯ä¿¡æ¯")
    created_at = Column(DateTime, server_default=text("NOW()"), comment="åˆ›å»ºæ—¶é—´")
    updated_at = Column(DateTime, server_default=text("NOW()"), onupdate=text("NOW()"), comment="æ›´æ–°æ—¶é—´")

# å¼•å…¥æ¨¡å‹ç›¸å…³åº“
try:
    from funasr import AutoModel
    from modelscope import snapshot_download
except ImportError:
    logger.error("ç¼ºå°‘ funasr æˆ– modelscope ä¾èµ–ï¼Œè¯·æ‰§è¡Œ: pip install funasr modelscope")
    AutoModel = None
    snapshot_download = None

class SpeechManager:
    """
    è¯­éŸ³è¯†åˆ«ç®¡ç†å™¨ (å•ä¾‹æ¨¡å¼)
    è´Ÿè´£æ¨¡å‹åŠ è½½ã€æ¨ç†å’Œèµ„æºç®¡ç†
    """
    _instance = None
    _model = None
    _is_loading = False

    # æ¨¡å‹é…ç½®
    MODELS = {
        "asr": "iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "vad": "iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
        "punc": "iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch"
    }

    # è·¯å¾„é…ç½®
    BASE_MODEL_DIR = settings.BASE_DIR / "app" / "models" / "speech_model"
    TEMP_DIR = settings.BASE_DIR / "temp"

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def __init__(self):
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        if not self.TEMP_DIR.exists():
            self.TEMP_DIR.mkdir(parents=True, exist_ok=True)
        
        # å¼ºåˆ¶ CPU é…ç½® (å‚è€ƒåŸ 1.py)
        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
        self.device = "cpu"

    async def initialize(self):
        """
        åˆå§‹åŒ–æ¨¡å‹ï¼šæ£€æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ä¸‹è½½ï¼Œç„¶ååŠ è½½
        """
        if self._model:
            logger.info("âœ… [Speech] æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return

        if self._is_loading:
            logger.warning("âš ï¸ [Speech] æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨å€™...")
            while self._is_loading:
                await asyncio.sleep(1)
            return

        self._is_loading = True
        try:
            logger.info("ğŸš€ [Speech] å¼€å§‹åˆå§‹åŒ–è¯­éŸ³æ¨¡å‹ (CPUæ¨¡å¼)...")
            
            # 1. å‡†å¤‡æ¨¡å‹è·¯å¾„
            model_paths = {}
            for key, model_id in self.MODELS.items():
                # ä½¿ç”¨æ¨¡å‹IDçš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæœ¬åœ°ç›®å½•å
                local_name = model_id.split("/")[-1]
                local_path = self.BASE_MODEL_DIR / local_name
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                if not local_path.exists():
                    logger.info(f"ğŸ“¥ [Speech] æ¨¡å‹æœªæ‰¾åˆ°ï¼Œå¼€å§‹ä¸‹è½½: {model_id} -> {local_path}")
                    try:
                        # è‡ªåŠ¨ä¸‹è½½åˆ°æŒ‡å®šç›®å½•
                        download_path = snapshot_download(model_id, cache_dir=str(self.BASE_MODEL_DIR))
                        # snapshot_download é»˜è®¤ä¼šä¸‹è½½åˆ° cache_dir/model_idï¼Œæˆ‘ä»¬éœ€è¦ç¡®è®¤å®é™…è·¯å¾„
                        # è¿™é‡Œç›´æ¥ä½¿ç”¨ snapshot_download è¿”å›çš„è·¯å¾„å³å¯
                        model_paths[key] = download_path
                        logger.success(f"âœ… [Speech] æ¨¡å‹ä¸‹è½½å®Œæˆ: {key}")
                    except Exception as e:
                        logger.error(f"âŒ [Speech] æ¨¡å‹ä¸‹è½½å¤±è´¥ {model_id}: {e}")
                        raise e
                else:
                    # å¦‚æœæ‰‹åŠ¨æ”¾ç½®äº†ç›®å½•ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ (éœ€ç¬¦åˆ funasr ç»“æ„)
                    # ä¸ºå…¼å®¹ snapshot_download çš„ç¼“å­˜ç»“æ„ï¼Œå»ºè®®è¿˜æ˜¯é€šè¿‡ snapshot_download æ£€æŸ¥
                    # è¿™é‡Œä¸ºäº†ç¨³å¥ï¼Œæˆ‘ä»¬å†æ¬¡è°ƒç”¨ snapshot_downloadï¼Œå®ƒä¼šè‡ªåŠ¨è·³è¿‡å·²ä¸‹è½½çš„æ–‡ä»¶
                    logger.info(f"ğŸ” [Speech] æ ¡éªŒæœ¬åœ°æ¨¡å‹: {local_path}")
                    model_paths[key] = snapshot_download(model_id, cache_dir=str(self.BASE_MODEL_DIR))

            # 2. åŠ è½½æ¨¡å‹
            logger.info("ğŸ”„ [Speech] æ­£åœ¨åŠ è½½ FunASR æ¨¡å‹...")
            self._model = AutoModel(
                model=model_paths["asr"],
                vad_model=model_paths["vad"],
                punc_model=model_paths["punc"],
                device=self.device,
                disable_update=True,  # å·²æ‰‹åŠ¨ä¸‹è½½ï¼Œç¦æ­¢è‡ªåŠ¨æ›´æ–°
                nproc=1,              # CPU å•è¿›ç¨‹
                trust_remote_code=False,
                disable_pbar=True
            )
            logger.success("âœ… [Speech] æ¨¡å‹åŠ è½½æˆåŠŸï¼")

        except Exception as e:
            logger.error(f"âŒ [Speech] æ¨¡å‹åŠ è½½å¤±è´¥: {traceback.format_exc()}")
            self._model = None
        finally:
            self._is_loading = False

    async def transcribe_file(self, file: UploadFile, current_user, db) -> dict:
        """
        æ–‡ä»¶è½¬å†™ (å« S3 ä¸Šä¼ å’Œ DB è®°å½•)
        """
        if not self._model:
            await self.initialize()
            if not self._model:
                return {"status": "error", "message": "æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æŸ¥çœ‹åå°æ—¥å¿—"}

        # 1. ä¸Šä¼ æ–‡ä»¶åˆ° S3 / æœ¬åœ°
        try:
            # å‡è®¾å­˜å‚¨åœ¨ speech æ¨¡å—ä¸‹
            url, object_key, size = await UploadUtils.save_file(file, module="speech")
        except Exception as e:
            logger.error(f"âŒ [Speech] æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
            return {"status": "error", "message": f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"}

        # 2. å‡†å¤‡æœ¬åœ°ä¸´æ—¶æ–‡ä»¶ç”¨äºæ¨ç† (å› ä¸º funasr éœ€è¦æœ¬åœ°è·¯å¾„)
        # å¦‚æœæ˜¯ S3 æ¨¡å¼ï¼Œsave_file è¿”å›çš„æ˜¯ keyï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°ä¸‹è½½æµæˆ–è€…
        # ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¼ å‰/åä¿ç•™ä¸€ä¸ªæœ¬åœ°å‰¯æœ¬ç”¨äºæ¨ç†ï¼Ÿ
        # UploadUtils.save_file ä¼šå…³é—­ file streamã€‚
        # æˆ‘ä»¬å¯ä»¥ä¿®æ”¹ UploadUtils æˆ–è€…åœ¨è¿™é‡Œé‡æ–°è·å–æµã€‚
        # ç®€å•èµ·è§ï¼š
        # æ–¹æ¡ˆ A: ä½¿ç”¨ save_file è¿”å›çš„ url (å¦‚æœæ˜¯ http) -> ä¸è¡Œï¼Œfunasr éœ€è¦æœ¬åœ°è·¯å¾„
        # æ–¹æ¡ˆ B: å†æ¬¡è¯»å– file (UploadFile æ”¯æŒ seek(0) å—ï¼Ÿspooled file å¯ä»¥)
        # æ–¹æ¡ˆ C: å…ˆä¿å­˜åˆ° tempï¼Œç„¶åä¸Šä¼  S3ï¼Œç„¶åæ¨ç†ã€‚
        
        # é‡æ–° seek file (UploadUtils.save_file ä¼š close å—ï¼Ÿcheck UploadUtils code)
        # UploadUtils code shows `await file.close()` in finally block. 
        # So file is closed. We cannot read it again.
        
        # Strategy: We must read content first, or modify UploadUtils.
        # But we can't easily modify UploadUtils without affecting others.
        # Alternative: We can use `UploadUtils.get_file_stream(object_key)` to download it back to temp.
        
        temp_file_path = self.TEMP_DIR / f"{uuid.uuid4()}{os.path.splitext(file.filename)[1]}"
        
        try:
            # ä» S3/Local ä¸‹è½½å›ä¸´æ—¶æ–‡ä»¶ç”¨äºæ¨ç†
            # æˆ–è€…ï¼Œæ›´é«˜æ•ˆçš„åšæ³•æ˜¯ï¼šæˆ‘ä»¬è‡ªå·±å…ˆå­˜ tempï¼Œç„¶åä¼ ç»™ UploadUtils (ä½† UploadUtils æ¥æ”¶ UploadFile)
            # Let's use get_file_stream to be safe and compatible with S3
            
            # Write temp file from S3/Local stream
            with open(temp_file_path, "wb") as f:
                 async for chunk in UploadUtils.get_file_stream(object_key):
                     f.write(chunk)
            
            # 3. æ¨ç†
            logger.info(f"ğŸ¤ [Speech] å¼€å§‹è½¬å†™æ–‡ä»¶: {file.filename}")
            # è®¡ç®—æ—¶é•¿ (å¯é€‰ï¼Œéœ€è¦éŸ³é¢‘åº“)
            duration = 0.0 
            
            res = self._model.generate(input=str(temp_file_path), batch_size_s=300)
            text_result = res[0].get("text", "") if (res and len(res) > 0) else ""
            
            # 4. å­˜å…¥æ•°æ®åº“
            log_entry = SpeechLog(
                user_id=current_user.username, # å‡è®¾ current_user æœ‰ username
                audio_url=url,
                s3_key=object_key,
                recognition_text=text_result,
                duration=duration,
                status="success"
            )
            db.add(log_entry)
            await db.commit()
            await db.refresh(log_entry)
            
            return {
                "code": 200,
                "msg": "success",
                "data": {
                    "text": text_result,
                    "url": url,
                    "id": str(log_entry.id)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ [Speech] å¤„ç†å‡ºé”™: {e}")
            # è®°å½•å¤±è´¥æ—¥å¿—
            try:
                err_log = SpeechLog(
                    user_id=current_user.username,
                    audio_url=url, # URL ä¾ç„¶æœ‰æ•ˆ
                    s3_key=object_key,
                    recognition_text="",
                    status="failed",
                    error_msg=str(e)
                )
                db.add(err_log)
                await db.commit()
            except:
                pass
                
            return {"code": 500, "msg": f"å¤„ç†å¤±è´¥: {str(e)}"}
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path.exists():
                os.remove(temp_file_path)

    async def handle_websocket(self, websocket: WebSocket):
        """
        WebSocket å®æ—¶è½¬å†™å¤„ç†
        """
        await websocket.accept()
        logger.info(f"ğŸ”Œ [Speech] WebSocket è¿æ¥å»ºç«‹: {websocket.client}")

        if not self._model:
            await self.initialize()
            if not self._model:
                await websocket.close(code=1011, reason="æ¨¡å‹æœªåŠ è½½")
                return

        audio_buffer = bytearray()
        try:
            while True:
                message = await websocket.receive()
                
                if "text" in message:
                    try:
                        data = json.loads(message["text"])
                        # æ”¯æŒç»“æŸä¿¡å·
                        if not data.get("is_speaking", True):
                            break
                    except:
                        pass
                
                elif "bytes" in message:
                    audio_chunk = message["bytes"]
                    audio_buffer.extend(audio_chunk)
                    
                    # ç®€å•çš„ç¼“å†²ç­–ç•¥ï¼šæ¯ç§¯æ”’ä¸€å®šé‡æ•°æ®è¿›è¡Œä¸€æ¬¡å¿«é€Ÿæ¨ç† (æ¨¡æ‹Ÿæµå¼ï¼Œå®é™…æ˜¯ä¼ªæµå¼)
                    # åŸ 1.py é€»è¾‘ï¼šlen(audio_buffer) % 32000 < len(audio_chunk)
                    # è¿™é‡Œçš„é€»è¾‘æ˜¯å¤§çº¦æ¯ 1-2 ç§’çš„æ•°æ®æ¨ä¸€æ¬¡
                    if len(audio_buffer) % 32000 < len(audio_chunk):
                        audio_np = np.frombuffer(audio_buffer, dtype=np.int16).astype(np.float32)
                        # æ³¨æ„ï¼šAutoModel çš„ generate åœ¨ CPU ä¸Šå¯èƒ½è¾ƒæ…¢ï¼Œé¢‘ç¹è°ƒç”¨ä¼šé˜»å¡
                        # è¿™é‡Œæ²¿ç”¨åŸé€»è¾‘
                        res = self._model.generate(input=audio_np, batch_size_s=300)
                        text = res[0].get("text", "") if (res and len(res) > 0) else ""
                        
                        if text:
                            await websocket.send_text(json.dumps({
                                "text": text,
                                "mode": "2pass-online",
                                "is_final": False
                            }))

        except WebSocketDisconnect:
            logger.info("ğŸ”Œ [Speech] WebSocket è¿æ¥æ–­å¼€")
        except Exception as e:
            logger.error(f"âŒ [Speech] WebSocket å¼‚å¸¸: {e}")
        finally:
            # æœ€ç»ˆå¤„ç†ï¼ˆå¤„ç†å‰©ä½™ bufferï¼‰
            if len(audio_buffer) > 0 and self._model:
                try:
                    audio_np = np.frombuffer(audio_buffer, dtype=np.int16).astype(np.float32)
                    res = self._model.generate(input=audio_np, batch_size_s=300)
                    text = res[0].get("text", "") if (res and len(res) > 0) else ""
                    await websocket.send_text(json.dumps({
                        "text": text,
                        "mode": "2pass-offline",
                        "is_final": True
                    }))
                except Exception as e:
                    logger.error(f"âŒ [Speech] æœ€ç»ˆæ¨ç†å¤±è´¥: {e}")

# å…¨å±€å•ä¾‹
speech_service = SpeechManager()
